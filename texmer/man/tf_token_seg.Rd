% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/token.R
\name{tf_token_seg}
\alias{tf_token_seg}
\title{Segment text into segments with fixed number of tokens.}
\usage{
tf_token_seg(corpus, seg_size)
}
\arguments{
\item{corpus}{A data frame containing columns 'id' and 'token'. See 'details' for more information.}

\item{seg_size}{An integer determining the maximum number of tokens per segment.}
}
\value{
A data frame with 'token' replaced by the segments in 'text'. 'id' contains the new ids and the old ids are preserved in 'docid'.
}
\description{
Segments each document in a corpus based on a fixed maximum number of tokens per segment.
}
\details{
The input corpus is expected to have a column 'id' that is equal for each token of the same document, i.e., it identifies which document each token is part of.
}
