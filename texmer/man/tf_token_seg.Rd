% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/token.R
\name{tf_token_seg}
\alias{tf_token_seg}
\title{Segment text into segments with fixed number of tokens.}
\usage{
tf_token_seg(corpus, seg_size, token = "words", ...)
}
\arguments{
\item{corpus}{A data frame containing columns 'id' and 'text'}

\item{seg_size}{An integer determining the maximum number of tokens per segment}

\item{token}{The definition of token. See \code{\link[tidytext]{unnest_tokens}} for options.}
}
\description{
Segments each document in a corpus based on a fixed maximum number of tokens per segment.
}
