% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/token.R
\name{tf_token_seg}
\alias{tf_token_seg}
\title{Token Segmentizer}
\usage{
tf_token_seg(corpus, seg_size, tokenized_corpus = NULL, token = "words",
  ...)
}
\description{
Segments a corpus based on a fixed number of tokens
}
